<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>A brief introduction to machine learning and its potential applications to CFD</title>

		<meta name="description" content="A brief introduction to machine learning">
		<meta name="author" content="Andre Weiner">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/white.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<!-- title slide -->
				<section>
					<h2>A brief introduction to machine learning and its potential application to CFD</h2>
					<p>
						<small>Andre Weiner, <a href="https://www.mma.tu-darmstadt.de/index/index.en.jsp">Mathematical Modeling and Analysis</a> (Chair of Prof. D. Bothe), TU Darmstadt</small><br>
						<small>Get in touch: <a href="mailto:weiner@mma.tu-darmstadt.de">weiner@mma.tu-darmstadt.de</a></small><br>
						<small>Slides available at: <a href="https://andreweiner.github.io/reveal.js/ofw2019_slides.html#/">andreweiner.github.io/reveal.js/ofw2019_slides.html</a></small><br>
						<small>Code and instructions: <a href="https://github.com/AndreWeiner/machine-learning-applied-to-cfd">github.com/AndreWeiner/machine-learning-applied-to-cfd</a></small>
					</p>
					<style>
						.row_img {
							display: table;
						}
						.column_img {
							display: table-cell;
							vertical-align: middle;
							text-align: center;
							width: 50%;
						}
						.content_img {
							display: inline-block;
						}
					</style>
					<div class="row_img">
 						<div class="column_img">
							<div class="content_img">
	 							<img src="images/mma_logo.jpg" alt="mma_logo" style="background:none; border:none; box-shadow:none;">
							</div>
 						</div>
 						<div class="column_img">
							<div class="content_img">
	 							<img src="images/spp1740_logo.svg" alt="spp1740_logo" style="background:none; border:none; box-shadow:none;">
							</div>
 						</div>
					</div>
				</section>

				<!-- warm up questions -->
				<section>
					<section>
						<h2>Some warm-up questions</h2>
						<p>
						<p style="color:red;">answer by a show of hands</p>
						</p>
					</section>
					<section>
						<h2>What is machine learning?</h2>
					</section>
					<section>
						<h2>Who has some hands-on experience with machine learning?</h2>
					</section>
					<section>
						<h2>Who uses machine learning professionally?</h2>
					</section>
					<section>
						<h2>Who knows the difference between ...</h2>
						<p>
							<ul>
								<li>Artificial intelligence</li>
								<li>Machine learning</li>
								<li>Deep learning</li>
							</ul>
						</p>
					</section>
					<section>
						<h2>Jupyter notebooks</h2>
						<p> <a href="https://www.anaconda.com/distribution/">learn more</a> </p>
					</section>
					<section>
						<h2>Google Colaboratory "colab"</h2>
						<p> <a href="https://colab.research.google.com/">learn more</a> </p>
					</section>
					<section>
						<h2>Docker</h2>
						<p> <a href="https://www.docker.com/why-docker">Why Docker?</a> </p>
					</section>
					<section>
						<h2>Basic Python knowledge</h2>
					</section>
					<section>
						<h2>Do you know <a href="https://pytorch.org/">PyTorch</a>? </h2>
					</section>
					<section>
						<h2>Who is working with PyTorch?</h2>
					</section>
				</section>

				<!-- outline -->
				<section>
					<h2>Outline</h2>
					<ol>
						<li>Machine learning terminology <span style="color:red;">~10min</span></li>
						<li>Classifying stability regions of bubbles <span style="color:red;">~30min</span></li>
						<li>Learning the shape of a bubble (4D) <span style="color:red;">~25min</span></li>
						<li>A PyTorch-based boundary condition <span style="color:red;">~25min</span></li>
						<hr> </hr>
						<li>Discussion: application of ML in your work</li>
						<li>Learning the shape of a bubble (2D)</li>
						<li>Detecting volume fragments</li>
					</ol>
				</section>

				<!-- questions -->
				<section>
					<h2>Its a training ...</h2>
					<p>Feel free to ask <span style="color:red;">questions</span> at any time!</p>
				</section>

				<!-- machine learning terminology -->
				<section>
					<section>
						<h2>Machine learning terminology</h2>
						<p>Just enough to get you started</p>
					</section>
					<section>
						<h2>Artificial intelligence (AI)</h2>
						<blockquote>
							&ldquo;[AI is] the theory and development of computer systems able to perform tasks normally requiring human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.&rdquo; <b>Wikipedia</b>
						</blockquote>
					</section>
					<section data-background-iframe="https://en.wikipedia.org/wiki/Deep_Blue_versus_Garry_Kasparov" data-background-interactive>
						<div style="position: absolute; width: 40%; right: 0; box-shadow: 0 1px 4px rgba(0,0,0,0.5), 0 5px 25px rgba(0,0,0,0.2); background-color: rgba(0, 0, 0, 0.9); color: #fff; padding: 20px; font-size: 20px; text-align: left;">
							<p>Deep Blue versus Garry Kasparov</p>
							<p>Deep Blue was the fist chess computer to beet the world chess champion Garry Kasparov.</p>
							<p>Source: <a href="https://en.wikipedia.org/wiki/Deep_Blue_versus_Garry_Kasparov">Wikipedia</a></p>
						</div>
					</section>
					<section data-background-iframe="https://mathpix.com/" data-background-interactive>
						<div style="position: absolute; width: 40%; right: 0; box-shadow: 0 1px 4px rgba(0,0,0,0.5), 0 5px 25px rgba(0,0,0,0.2); background-color: rgba(0, 0, 0, 0.9); color: #fff; padding: 20px; font-size: 20px; text-align: left;">
							<p>Mathpix</p>
							<p>Mathpix can tranform images of handwritten notes, PDFs or books to math (LaTex) and text.</p>
							<p>Source: <a href="https://mathpix.com/">www.mathpix.com</a></p>
						</div>
					</section>
					<section>
						<h2>Machine learning (ML)</h2>
						<blockquote>
							&ldquo;Machine learning is the science (and art) of programming computers so they can learn from data.&rdquo; <b>Aurélien Géron</b> (2017)
						</blockquote>
					</section>
					<section>
						<h2>Machine learning (ML)</h2>
						<blockquote>
							&ldquo;[Machine Learning is the] field of study that gives computers the ability to learn without being explicitly programmed.&rdquo; <b>Arthur Samuel</b> (1959)
						</blockquote>
					</section>
					<section>
						<h2>Machine learning (ML)</h2>
						<blockquote>
							&ldquo;A computer program is said to learn from experience E with respect to some Task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.&rdquo; <b>Tom Mitchel</b> (1997)
						</blockquote>
					</section>
					<section>
						<h2>Machine learning (ML)</h2>
						<blockquote>
							&ldquo;Tools and algorithms to generate function approximations (mappings) based on examples (function arguments and the corresponding function values).&rdquo; my personal point of view
						</blockquote>
					</section>

					<section>
						<img src="images/ai_ml_onion.svg" alt="AI ML onion" width="850" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<h2>Deep learning (DL)</h2>
						<blockquote>
							&ldquo;Tools and algorithms to create and optimize deep neural networks.&rdquo;
						</blockquote>
						<img src="images/combined_linear_models.svg" alt="Neural Network" width="450" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<img src="images/ai_ml_dl_onion.svg" alt="AI ML DL onion" width="850" style="background:none; border:none; box-shadow:none;">
					</section>

					<section data-background="images/formula1_car_transparent.png">
						<h2>Data with labels</h2>
						<table>
							<thead>
								<tr>
									<th><span style="color:red;">Feature 1</span> $Re$</th>
									<th><span style="color:red;">Feature 2</span> $A$</th>
									<th>...</th>
									<th><span style="color:green;">Label 1</span> $c_d$</th>
									<th><span style="color:green;">Label 2</span> regime</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>334</td>
									<td>0.832</td>
									<td>...</td>
									<td>0.123</td>
									<td>laminar</td>
								</tr>
								<tr>
									<td>2934</td>
									<td>0.943</td>
									<td>...</td>
									<td>0.384</td>
									<td>laminar</td>
								</tr>
								<tr>
									<td>12004</td>
									<td>1.263</td>
									<td>...</td>
									<td>0.573</td>
									<td>turbulent</td>
								</tr>
								<tr>
									<td>98204</td>
									<td>2.284</td>
									<td>...</td>
									<td>0.834</td>
									<td>turbulent</td>
								</tr>
								<tr>
									<td>...</td>
									<td>...</td>
									<td>...</td>
									<td>...</td>
									<td>...</td>
								</tr>
							</tbody>
						</table>
						<p>Image source: <a href="https://www.flickr.com/photos/kitware/2293740417">Kitware Inc., Flickr</a></p>
					</section>
					<section>
							<h2>Data without labels</h2>
							<table>
								<thead>
									<tr>
										<th><span style="color:red;">Feature 1</span> $Re$</th>
										<th><span style="color:red;">Feature 2</span> $A$</th>
										<th><span style="color:red;">Feature 3</span> $c_d$</th>
										<th><span style="color:red;">Feature 4</span> regime</th>
									</tr>
								</thead>
								<tbody>
									<tr>
										<td>334</td>
										<td>0.832</td>
										<td>0.123</td>
										<td>laminar</td>
									</tr>
									<tr>
										<td>2934</td>
										<td>0.943</td>
										<td>0.384</td>
										<td>laminar</td>
									</tr>
									<tr>
										<td>12004</td>
										<td>1.263</td>
										<td>0.573</td>
										<td>turbulent</td>
									</tr>
									<tr>
										<td>98204</td>
										<td>2.284</td>
										<td>0.834</td>
										<td>turbulent</td>
									</tr>
								</tbody>
							</table>
						</section>
						<section>
							<h2>Supervised learning</h2>
							<p>Learning based on pairs of <b>features</b> and <b>labels</b></p>
							<img src="images/regression_classification_web.svg" alt="Regression and Classification" width="800" style="background:none; border:none; box-shadow:none;">
						</section>
						<section>
							<h2><span style="color:red;">Un</span>supervised learning</h2>
							<p>Finding groups of similar data points</b></p>
							<img src="images/clustering_web.svg" alt="Clustering" width="800" style="background:none; border:none; box-shadow:none;">
						</section>
						<section>
							<h2>Reinforcement learning</h2>
							<img src="images/reinforcement_web.svg" alt="Reinforcement" width="800" style="background:none; border:none; box-shadow:none;">
						</section>
						<section>
							<h2>Active flow control for drag reduction</h2>
							<img src="videos/2D_flow_control.gif" alt="flow_control" width="700" style="background:none; border:none; box-shadow:none;">
							<p>Source: Jean Rabault et al., <a href="https://github.com/jerabaul29/Cylinder2DFlowControlDRL"> check out the code!</a></p>
						</section>
						<section>
							<h2>ML is interdisciplinary</h2>
							<p>
								<ul>
									<li>data analysis</li>
									<li>data visualization</li>
									<li>dimensionality reduction</li>
									<li>non-linear optimization</li>
									<li>high-performance computing</li>
									<li>probabilistic thinking</li>
									<li>domain knowledge</li>
									<li>...</li>
								</ul>
							</p>
						</section>
						<section>
							<h2>Why should you use ML?</h2>
							<h3 style="color:red;">Accuracy</h3>
							<p>and</p>
							<h3 style="color:red;">Performance</h3>
							<p>Leverage data that is already available!</p>
						</section>
						<section>
							<h2>When should you use DL?</h2>
							<ul>
								<li>high dimensional parameter spaces</li>
								<li>data is avaiable</li>
								<li>when you can live with small imperfections</li>
							</ul>
						</section>
						<section>
							<h2>When shouldn't you use DL?</h2>
							<ul>
								<li>classical approaches are available</li>
								<li>available data is insufficient or of low quality</li>
								<li>when you can <b>not</b> live with small imperfections</li>
							</ul>
						</section>
				</section>

				<!-- Hands-on: Jupyter -->
				<section>
					<section>
						<h2>Hans-on: Jupyter notebooks</h2>
						<pre><code data-trim data-line-numbers="1,2">
~$ git clone https://github.com/AndreWeiner/machine-learning-applied-to-cfd.git
~$ cd notebooks
~$ jupyter-notebook
						</code></pre>
						<img src="images/jupyter_start_screen.png" alt="Jupyter" width="850" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<small>
						<ol>
							<li><a href="https://colab.research.google.com">Go to colab.research.google.com</a></li>
							<li>Switch to the GITHUB tab</li>
							<li>Search for <b>AndreWeiner</b></li>
							<li>Select the repository <b>machine-learning-applied-...</b></li>
						</ol>
						</small>
						<img src="images/colab_import_from_github.png" alt="Jupyter" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
				</section>

				<!-- classification example -->
				<section>
					<section>
						<h2>Classifying stability regions of rising bubbles</h2>
						<p style="color:red;">path_regime_classification.ipynb</p>
					</section>
					<section>
						<img src="images/path_regimes.png" alt="path_regimes" width="700" style="background:none; border:none; box-shadow:none;">
						<p>Source: <a href="https://www.nature.com/articles/ncomms7268">M. K. Tripathi et al. 2015,</a> figure 1.</p>
					</section>
					<section>
						<img src="images/path_regime_data.png" alt="regime_data" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<h2>Manual binary classification</h2>
						<p>For now, consider only regions I and II.</p>
						<p>$$ z(Ga^\prime, Eo^\prime) = w_1Ga^\prime + w_2Eo^\prime + b $$</p>
						<p>$ Ga^\prime = log(Ga) $, $ Eo^\prime = log(Eo) $</p>
						<p>
							$$
								H(z (Ga^\prime, Eo^\prime)) = \left\{\begin{array}{lr}
						    0, & \text{if } z \leq 0\\
						    1, & \text{if } z \gt 0
						    \end{array}\right.
							$$
						</p>
					</section>
					<section>
						<p>$ w_1=8.0 $, $ w_2=1.0 $, $b=-12.0$</p>
						<img src="images/manual_binary_classification.png" alt="Jupyter" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<h2>Performance metric I</h2>
						<p>True label:
							$$
								y_i = \left\{\begin{array}{lr}
						    0, & \text{for region I }\\
						    1, & \text{for region II}
						    \end{array}\right.
							$$
						</p>
						<p>Predicted label:
							$$
								\hat{y}_i = H(z) = \left\{\begin{array}{lr}
						    0, & \text{if } z < 0\\
						    1, & \text{if } z \ge 0
						    \end{array}\right.
							$$
						</p>
					</section>
					<section>
						<h2>Performance metric II</h2>
						<p>Linearly weighted inputs
							$$
								z_i=z(X_i)=\sum\limits_{j=1}^{N_f}w_jX_{ij}+b
							$$
						</p>
						<p>with
							$$
								X_i = \left[ Ga^\prime_i, Eo^\prime_i \right],\quad w = \left[ w_1, w_2 \right]^T
							$$
						</p>
					</section>
					<section>
						<h2>Performance metric III</h2>
						<p>Loss function
							$$
								L(w) = \frac{1}{2}\sum\limits_{i=1}^N \left(y_i - \hat{y}_i(X_i,w) \right)^2
							$$
						</p>
						<p>The term in parenthesis can take the values<br>$1$, $0$, or $-1$.</p>
					</section>
					<section>
						<h2>Gradient decent</h2>
						<p>Simple update rule for the weights <small>
							$$
								w^{n+1} = w^n - \eta \frac{\partial L(w)}{\partial w} =
								\begin{pmatrix}w_1^n\\
									w_2^n\\
									b^n
								\end{pmatrix} + \eta
								\sum\limits_{i=1}^N \left(y_i - \hat{y}_i(X_i,w^n) \right)
								\begin{pmatrix}Ga^\prime_i\\
									Eo^\prime_i\\
									1
								\end{pmatrix}
							$$</small>
						</p>
						<p>$\eta$ - learning rate</p>
					</section>
					<section>
						<h2>Perceptron algorithm</h2>
						<pre class="python"><code data-trim data-line-numbers="5-11">
class SimpleClassifier():
  '''Implementation of a simple *perceptron* and the perceptron learning rule.
  '''
  ...
  def train(self, X, y):
    for e in range(self.epochs_):
      self.weights_ += self.eta_ * self.lossGradient(X, y)
      self.loss_.append(self.loss(X, y))
      if self.loss_[-1] < 1.0E-6:
        print("Training converged after {} epochs.".format(e))
        break
						</code></pre>
					</section>
					<section>
						<img src="images/perceptron_loss.png" alt="perceptron_loss" width="800" style="background:none; border:none; box-shadow:none;">
						<p>Why is the loss changing so randomly?
						<p>What would happen if the data was not linearly separable?</p>
					</section>
					<section>
						<img src="images/perceptron_classification.png" alt="perceptron_classification" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<h2>Conditional probabilities</h2>
						<p>
							What is probability of a point $X_i$ to be in region II
							$$ p(y_i=1|X_i) $$
						</p>
						<ul>
							<li>for points far in region II?</li>
							<li>for points far in region I?</li>
							<li>for points close to the decision boundary?</li>
						</ul>
					</section>
					<section>
						<h2>Sigmoid function</h2>
						<p>
							$$ \sigma_i = \sigma (z_i) = \frac{1}{1+e^{-z_i}} $$
						</p>
						<img src="images/sigmoid_function.png" alt="sigmoid" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<img src="images/logit_probabilities.png" alt="data_probabilities" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<h2>Maximum likelihood</h2>
						<p>
							For all points $i$:
						</p>
						<ul>
							<li>
								maximize $p(y_i=0|X_i)$ if $X_i$ in I
							</li>
							<li>
								maximize $p(y_i=1|X_i)$ if $X_i$ in II
							</li>
						</ul>
					</section>
					<section>
						<h2>Binary cross entropy</h2>
						<p><small>
							$$
  							L(w) = -\frac{1}{N}\sum\limits_{i=1}^N y_i \mathrm{ln}(\hat{y}_i(X_i,w)) + (1-y_i) \mathrm{ln}(1-\hat{y}_i(X_i,w))
							$$
							$ \hat{y}_i = \sigma (z(X_i,w)) $
							$$
								\frac{\partial L}{\partial w} = -\frac{1}{N}\sum\limits_{i=1}^N (y_i - \hat{y}_i)
								\begin{pmatrix}Ga^\prime_i\\
							 		Eo^\prime_i\\
							 		1
								\end{pmatrix}
							$$
						</small></p>
					</section>
					<section>
						<h2>Logistic regression</h2>
						<pre class="python"><code data-trim data-line-numbers="5-10">
class LogClassifier():
  '''Implemention of a logistic-regression classifier.
  '''
  ...
  def probability(self, X):
    z = np.dot(np.concatenate((X, np.ones((X.shape[0], 1))), axis=1), self.weights_)
    return 1.0 / (1.0 + np.exp(-z))

  def predict(self, X):
    return np.heaviside(self.probability(X) - 0.5, 0.0)
						</code></pre>
					</section>
					<section>
						<img src="images/logit_loss.png" alt="logit_loss" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<img src="images/logit_classification.png" alt="logit_classification" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<h2>Non-linear decision boundaries</h2>
						<img src="images/path_regime_data.png" alt="regime_data" width="600" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<pre class="python"><code data-trim data-line-numbers="2-3,6-7">
# classifier to separate region I and II
classifier_I_II = LogClassifier()
classifier_I_II.train(X_I_II, y_I_II, tol=0.1)
...
# classifier to separate region I and III
classifier_I_III = LogClassifier()
classifier_I_III.train(X_I_III, y_I_III, tol=0.05)
						</code></pre>
						<img src="images/two_linear_models.png" alt="two_linear_models" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<h2>Combining linear models</h2>
						<p>
							$ \hat{y}_{i,II,III} = \sigma (w_{21}\hat{y}_{i,II} + w_{22}\hat{y}_{i,III} + b_2) $
						</p>
						<img src="images/nonlinear_boundary.png" alt="nonlinear_boundary" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<img src="images/combined_linear_models.svg" alt="combined_models" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<h2>Multi-class classification I</h2>
						<p>
							One-hot encoding
						</p>
						<img src="images/one_hot_encoding.png" alt="one_hot" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<h2>Multi-class classification II</h2>
						<p>
							Softmax function for class $j$ with $K$ classes
							$$
  							p(y_{ij}=1 | X_i) = \frac{e^{z_{ij}}}{\sum_{j=0}^{K-1} e^{z_{ij}}}
							$$
						</p>
					</section>
					<section>
						<h2>Multi-class classification III</h2>
						<p>
							Categorial cross entropy for point $i$ and class $j$
							$$
  							L(w) = -\frac{1}{N} \sum\limits_{j=0}^{K-1}\sum\limits_{i=1}^{N} y_{ij} \mathrm{ln}\left( \hat{y}_{ij} \right)
							$$
						</p>
					</section>
					<section>
						<h2>PyTorch</h2>
						<ul>
							<li>
								Deep-learning framework
							</li>
							<li>
								layers, optimizers, automatic diff., ...
							</li>
							<li>
								frontend: Python and C++
							</li>
							<li>
								backend: C++ and Cuda
							</li>
							<li><span style="color:red;">
								easy model serialization
							</span></li>
						</ul>
					</section>
					<section>
						<h2>PyTorch classifier</h2>
						<pre class="python"><code data-trim data-line-numbers="1-15">
class PyTorchClassifier(nn.Module):
  '''Multi-layer perceptron with 3 hidden layers.
  '''
  def __init__(self, n_features=2, n_classes=5, n_neurons=60, activation=torch.sigmoid):
    super().__init__()
    self.activation = activation
    self.layer_1 = nn.Linear(n_features, n_neurons)
    self.layer_2 = nn.Linear(n_neurons, n_neurons)
    self.layer_3 = nn.Linear(n_neurons, n_classes)

  def forward(self, x):
    x = self.activation(self.layer_1(x))
    x = self.activation(self.layer_2(x))
    return F.log_softmax(self.layer_3(x), dim=1)
						</code></pre>
					</section>
					<section>
						<h2>Training loop</h2>
						<pre class="python"><code data-trim data-line-numbers="1-20">
regimeClassifier = PyTorchClassifier()
# categorial cross entropy taking logarithmic probabilities
criterion = nn.NLLLoss()
# stochastic gradient decent: ADAM
optimizer = optim.Adam(regimeClassifier.parameters(), lr=0.005)
...
# convert feature and label arrays into PyTorch tensors
featureTensor = torch.from_numpy(np.float32(logData[["Ga", "Eo"]].values))
labelTensor = torch.tensor(y_numeric, dtype=torch.long)

for e in range(1, epochs):
  optimizer.zero_grad()
  # run forward pass through the network
  log_prob = regimeClassifier(featureTensor)
  # compute cross entropy
  loss = criterion(log_prob, labelTensor)
  # compute gradient of the loss function w.r.t. to the model weights
  loss.backward()
  # update weights
  optimizer.step()
						</code></pre>
					</section>
					<section>
						<img src="images/multiclass_classification.png" alt="multiple_classes" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
				</section>

				<!-- regression example -->
				<section>
					<section data-background-video="videos/plic_with_background.ogv">
						<h2 style="position: absolute;top: -300px;">Learning the shape of a bubble</h2>
					</section>
					<section>
						<h2>GPU support in colab</h2>
						<ol>
							<li><span style="color:red;">4D_shape_approximation.ipynb</span></li>
							<li>Edit -> Notebook settings</li>
							<li>Hardware accelerator -> select GPU</li>
							<li>Check: <b>Executing PyTorch operations using cuda.</b></li>
						</ol>
					</section>
					<section>
						<h2>The data set</h2>
						<img src="images/4D_shape_data_set.png" alt="4D_data_set" width="600" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<h2>Shape parameterization</h2>
						<p>
							$ p(x_i,y_i,z_i,t_i) \rightarrow r(\varphi_i, \vartheta_i, t_i) $
						</p>
						<img src="images/4D_bubble_cartesian_polar_plot.png" alt="bubble_data_plot" width="600" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<img src="images/3D_polar_coord_plot.png" alt="3D_polar_plot" width="650" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<h2>Using domain knowledge</h2>
						<p>
							The shape will be always roughly ellipsoidal.<br />
							How can be use this knowledge?
						</p>
						<pre class="python"><code data-trim data-line-numbers="1-10">
def estimate_half_axis(x, y, z):
  ''' Estimate the half axis of an ellipsoid from a point cloud.'''
  ...
  a = 0.5 * (np.amax(x) - np.amin(x))
  b = 0.5 * (np.amax(y) - np.amin(y))
  c = 0.5 * (np.amax(z) - np.amin(z))
  return a, b, c
						</code></pre>
					</section>
					<section>
						<p>
							half-axis mapping $ f:\mathbb{R^1}\rightarrow\mathbb{R^3} $
						</p>
						<img src="images/aspect_ratio_time.png" alt="aspect_over_time" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
							<h2>Function approximator</h2>
							<pre class="python"><code data-trim data-line-numbers="1-30">
class SimpleMLP(torch.nn.Module):
  def __init__(self, n_inputs=1, n_outputs=1, n_layers=1, n_neurons=10, activation=torch.sigmoid, batch_norm=False):
    super().__init__()
    self.n_inputs = n_inputs
    self.n_outputs = n_outputs
    self.n_layers = n_layers
    self.n_neurons = n_neurons
    self.activation = activation
    ...
    # input layer to first hidden layer
    self.layers.append(torch.nn.Linear(self.n_inputs, self.n_neurons))
    # add more hidden layers if specified
    if self.n_layers > 1:
    for hidden in range(self.n_layers-1):
      self.layers.append(torch.nn.Linear(self.n_neurons, self.n_neurons))
    # last hidden layer to output layer
    self.layers.append(torch.nn.Linear(self.n_neurons, self.n_outputs))
    print("Created model with {} weights.".format(self.model_parameters()))

  def forward(self, x):
...
    for i_layer in range(len(self.layers)-1):
      x = self.activation(self.layers[i_layer](x))
      return self.layers[-1](x)

  def model_parameters(self):
    return sum(p.numel() for p in self.parameters() if p.requires_grad)
							</code></pre>
					</section>
					<section>
							<h2>Training loop</h2>
							<pre class="python"><code data-trim data-line-numbers="1-40">
def approximate_function(x_train, y_train, x_val, y_val, model, l_rate=0.001, batch_size=128,
                         max_iter=1000, path=None, device='cpu', verbose=100):
  ...
  # convert numpy arrays to torch tensors
  x_train_tensor = torch.from_numpy(x_train.astype(np.float32))
  y_train_tensor = torch.from_numpy(y_train.astype(np.float32))
  ...
  # define loss function
  criterion = torch.nn.MSELoss()
  # define optimizer
  optimizer = torch.optim.Adam(params=model.parameters(), lr=l_rate)
  ...
  # move model and data to gpu if available
  model.to(device)

  for e in range(1, max_iter+1):
    # backpropagation
    model = model.train()
    loss_sum_batches = 0.0
    for b in range(int(n_batches)):
      x_batch = x_train_tensor[b*batch_size:min(x_train_tensor.shape[0], (b+1)*batch_size)].to(device)
      y_batch = y_train_tensor[b*batch_size:min(x_train_tensor.shape[0], (b+1)*batch_size)].to(device)
      optimizer.zero_grad()
	    output_train = model(x_batch)
      loss_train = criterion(output_train.squeeze(dim=1), y_batch)
      loss_train.backward()
      optimizer.step()
      loss_sum_batches += loss_train.item()
      history_train.append(loss_sum_batches / n_batches)
...
    if history_train[-1] < best_loss:
      best_loss = history_train[-1]
      if path is not None:
        torch.save(model.state_dict(), path)
  return model.eval(), np.asarray(history_train), np.asarray(history_val)
							</code></pre>
					</section>
					<section>
						<pre class="python"><code data-trim data-line-numbers="1-10">
axis_model = SimpleMLP(n_inputs=1, n_outputs=3, n_layers=2, n_neurons=10,
                       activation=torch.sigmoid, batch_norm=False)
...
axis_model, train_loss, val_loss = \
     approximate_function(X_train, axis_train, X_val, axis_val,
        axis_model, max_iter=10000, l_rate=0.01, batch_size=100,
        path=set_path("3mm_axis_model.pt"), device='cpu', verbose=1000)
						</code></pre>
						<img src="images/aspect_ratio_approx.png" alt="aspect_approximation" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<p>
							$$ \tilde{r}_i = r_i / r_{elli} $$
						</p>
						<pre class="python"><code data-trim data-line-numbers="1-10">
def ellipsoidal_radius(phi, theta, t, axis_model):
  '''Compute the radius of an ellipsoid with instantaneous half axis.'''
...
  t_tensor = torch.from_numpy(t.astype(np.float32))
   a, b, c = axis_model(t_tensor).detach().numpy().T
   radius = np.sqrt(np.square(a * np.sin(phi) * np.cos(theta))
                  + np.square(b * np.cos(phi))
                  + np.square(c * np.sin(phi) * np.sin(theta)))
   return radius
						</code></pre>
						<p>
							Mean/stdev of original radius: 0.5306/0.0938 <br />
							Mean/stdev of rescaled radius: 0.9090/0.0965<br />
							Mean/stdev of rescaled radius [0,1]: 0.5877/0.1882
						</p>
					</section>
					<section>
						<h2>Training, validation, and test data</h2>
						<pre class="python"><code data-trim data-line-numbers="1-10">
X = np.vstack([phi, theta, data.t.values]).T
X_train, X_tv, r_train, r_tv = train_test_split(X, data.rad_01.values, test_size=0.2, random_state=42)
X_val, X_test, r_val, r_test = train_test_split(X_tv, r_tv, test_size=0.5, random_state=42)
...
"The training set contains 934983 points."
"The validation set contains 116873 points."
"The test set contains 116873 points."
						</code></pre>
					</section>
					<section>
						<pre class="python"><code data-trim data-line-numbers="1-10">
radius_model = SimpleMLP(n_inputs=3, n_outputs=1, n_layers=8, n_neurons=40, activation=torch.relu, batch_norm=False)
radius_model, train_loss, val_loss = approximate_function(X_train, r_train, X_val, r_val, radius_model, max_iter=1000,
    l_rate=0.001, batch_size=50000, path=set_path("3mm_radius_model.pt"), device=device, verbose=10)
						</code></pre>
						<img src="images/4D_shape_loss.png" alt="shape_loss" width="800" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<p>
							Test set: aximum/mean relative error 4.42/0.29 %
						</p>
						<img src="images/radius_error.png" alt="radius_error" width="1000" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<h2>Final model</h2>
						<pre class="python"><code data-trim data-line-numbers="1-30">
class ShapeModel(torch.nn.Module):
  def __init__(self, axis_model, radius_model, rs_min, rs_max,):
  super().__init__()
  self.axis_model = axis_model
  self.radius_model = radius_model
  self.rs_min = torch.tensor(rs_min, dtype=torch.float32)
  self.rs_max = torch.tensor(rs_max, dtype=torch.float32)

  def forward(self, x):
    # scaled model radius
    rs = self.radius_model(x).squeeze(1)
    # ellipsoidal radius
    re = self.ellipsoidal_radius(x)
    # transform back
    r = (rs * (self.rs_max - self.rs_min) + self.rs_min) * re
    return r

  def ellipsoidal_radius(self, x):
    axis = self.axis_model(x[:,2].unsqueeze(-1))
    re = torch.sqrt(
         (axis[:,0] * torch.sin(x[:,0]) * torch.cos(x[:,1]))**2
       + (axis[:,1] * torch.cos(x[:,0]))**2
       + (axis[:,2] * torch.sin(x[:,0]) * torch.sin(x[:,1]))**2
       )
    return re
						</code></pre>
					</section>
					<section>
						<h2>Tracing the model</h2>
						<pre class="python"><code data-trim data-line-numbers="1-30">
traced_shape_model = torch.jit.trace(shape_model, X_0_tensor[0].unsqueeze(0))
traced_shape_model.save(set_path("shape_model.pt"))
						</code></pre>
						<p>
							It is really that simple!
						</p>
					</section>
				</section>

				<!-- PyTorch and OpenFOAM -->
				<section>
					<section>
						<h2>A PyTorch-based boundary condition in OpenFOAM&reg;</h2>
					</section>
					<section>
						<h2>Why a Docker image?</h2>
						<p>
							Compiling OF + PyTorch requires to re-compile OF with<br />
							<b>-D_GLIBCXX_USE_CXX11_ABI=0</b><br />
							For details, check out the <a href="https://github.com/AndreWeiner/of_pytorch_docker">Github repo</a> for the Dockerfile.
						</p>

					</section>
					<section>
						<p>Pull the Docker image and create a container</p>
						<pre class="bash"><code data-trim data-line-numbers="1-7">
# pull the image from Dockerhub
# (use sudo if your user is not in the docker group)
~$ docker pull andreweiner/of_pytorch:of1906-py1.1-cpu
~$ cd ../OpenFOAM
~$ ls
apps  cases  runContainer.sh
~$ ./runContainer
						</code></pre>
						<p>Working directory in the container</p>
						<pre class="bash"><code data-trim data-line-numbers="1-3">
weiner@01f4d1ff183a:/home$ ls
apps  cases  runContainer.sh
						</code></pre>
					</section>
					<section>
						<p>First things first</p>
						<pre class="bash"><code data-trim data-line-numbers="1-3">
~$ source /opt/OpenFOAM/OpenFOAM-v1906/etc/bashrc
~$ cd apps/pyTorchDisplacement/
						</code></pre>
						<p>In pyTorchDisplacementPointPatchVectorField.H</p>
						<pre class="cpp"><code data-trim data-line-numbers="1-6">
#include &lt;torch/script.h&gt;
...
// private data
vector center_;
word model_name_;
std::shared_ptr&lt;torch::jit::script::Module&gt; pyTorch_model_;
						</code></pre>
					</section>
					<section>
						<p>In pyTorchDisplacementPointPatchVectorField.C</p>
						<pre class="cpp"><code data-trim data-line-numbers="8-12">
pyTorchDisplacementPointPatchVectorField::
pyTorchDisplacementPointPatchVectorField
(
...
)
:
  fixedValuePointPatchField&lt;vector&gt;(p, iF, dict),
  center_(dict.lookup("center")),
  model_name_(dict.lookupOrDefault&lt;word&gt;("model", "shape_model.pt"))
{
  pyTorch_model_ = torch::jit::load(model_name_);
  assert(pyTorch_model_ != nullptr);
  ...
}
						</code></pre>
					</section>
					<section>
						<p>In pyTorchDisplacementPointPatchVectorField.C</p>
						<pre class="cpp"><code data-trim data-line-numbers="4,16-18,20-23,27-28">
void pyTorchDisplacementPointPatchVectorField::updateCoeffs()
{
  ...
  torch::Tensor featureTensor = torch::ones({localPoints.size(), 3});
  forAll(localPoints, i)
  {
    scalar pi = constant::mathematical::pi;
    vector x = localPoints[i] - center_;
    scalar r = sqrt(x & x);
    scalar phi = acos(x.y() / r);
    scalar theta = std::fmod((atan2(x.x(), x.z()) + pi), pi);
    if (x.x() &lt; 0.0)
    {
      phi = 2.0 * pi - phi;
    }
    featureTensor[i][0] = phi;
    featureTensor[i][1] = theta;
    featureTensor[i][2] = t.value();
  }
  std::vector&lt;torch::jit::IValue&gt; modelFeatures{featureTensor};
  torch::Tensor radTensor = pyTorch_model_-&gt;forward(modelFeatures).toTensor();
  auto radAccessor = radTensor.accessor&lt;float,1&gt;();
  vectorField result(localPoints.size(), Zero);
  forAll(result, i)
  {
  vector x = localPoints[i] - center_;
  result[i] = x / mag(x) * (radAccessor[i] - mag(x));
  }
  Field&lt;vector&gt;::operator=(result);
  ...
}
						</code></pre>
					</section>
					<section>
						<h2>Compile the BC</h2>
						<pre class="bash"><code data-trim data-line-numbers="1-20">
EXE_INC = \
... \
-I$(TORCH_LIBRARIES)/include \
-I$(TORCH_LIBRARIES)/include/torch/csrc/api/include
...
EXE_LIBS = \
...\
-rdynamic \
-Wl,-rpath,$(TORCH_LIBRARIES)/lib $(TORCH_LIBRARIES)/lib/libtorch.so $(TORCH_LIBRARIES)/lib/libc10.so \
-Wl,--no-as-needed,$(TORCH_LIBRARIES)/lib/libcaffe2.so \
-Wl,--as-needed $(TORCH_LIBRARIES)/lib/libc10.so \
-lpthread
						</code></pre>
						<pre class="bash"><code data-trim data-line-numbers="1">
~$ wmake
						</code></pre>
						<p>
							Don't worry about the warning messages!
						</p>
					</section>
					<section>
						<h2>moving_boundary</h2>
						<pre class="bash"><code data-trim data-line-numbers="1-3">
~$ cd ../../cases/moving_boundary
~$ ls
0  Allclean  Allrun  constant  shape_model.pt  system
						</code></pre>
						<p>
							system/controlDict
						</p>
						<pre class="cpp"><code data-trim data-line-numbers="1-3">
libs ( "libPyTorchMotion.so");
						</code></pre>
						<p>
							0/pointDisplacement
						</p>
						<pre class="cpp"><code data-trim data-line-numbers="1-10">
wall
{
  type     pyTorchDisplacement;
  center   (0 0 0);
  model    "shape_model.pt";
  value    uniform (0 0 0);
}
						</code></pre>
					</section>
					<section>
						<h2>Clip of initial mesh</h2>
						<img src="images/initial_sphere_mesh.png" alt="initial_mesh" width="500" style="background:none; border:none; box-shadow:none;">
					</section>
					<section>
						<video height="600px" controls autoplay loop>
							<source src="videos/mesh_deformation.ogv">
						</video>
					</section>
				</section>

				<section style="text-align: left;">
					<h1>THE END</h1>
					<p><b>Thanks @mma:</b> Dennis Hillenbrand, Dirk Gründing, Johannes Kromer, Mathis Fricke, Matthias Niethammer, Tobias Tolle, Tomislav Marić</p>
					<p><b>Thanks to you!</b> Let me know what you think!</p>
					<p>Get in touch: <a href="mailto:weiner@mma.tu-darmstadt.de">weiner@mma.tu-darmstadt.de</a></p>
					<p><b>Time for discussion ...</b></p>
				</section>

			</div>

		</div>

		<script src="js/reveal.js"></script>

		<script>

			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				center: true,
				hash: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true },
					{ src: 'plugin/search/search.js', async: true },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/math/math.js', async: true }
				]
			});

		</script>

	</body>
</html>
